The Transformer architecture has demonstrated an unprecedented capacity to encode human language and knowledge. It effectively generates heuristics to predict the next token in a sequence of tokens, based on the context of the sentence. These heuristics can be tuned to respond to various strategies, such as text completion, agent, or assistant.

These properties make the Transformer architecture an intriguing tool for a chess engine. In fact, the approach used in other engines like AlphaZero is built around a heuristic engine that helps reduce the vast number of possible moves in complex games like chess. 

For this project, my main idea is to explore the capability to create a model capable of providing a suitable level of heuristics to play chess at a high Elo level.